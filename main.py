# -*- coding: utf-8 -*-
import os
import yaml
import argparse
from tutor_agent import TutorAgent
from vector_store import load_and_chunk, build_or_load, reset_db
from prompt import tutor_guideline

CFG = yaml.safe_load(open("config.yaml", encoding="utf-8"))

def convert_to_text(filepath: str) -> str:
    ext = os.path.splitext(filepath)[-1].lower()

    if ext == ".pdf":
        import fitz  # PyMuPDF
        text = ""
        with fitz.open(filepath) as doc:
            for page in doc:
                text += page.get_text()
        return text

    elif ext == ".docx":
        from docx import Document
        doc = Document(filepath)
        return "\n".join([para.text for para in doc.paragraphs])

    elif ext == ".pptx":
        from pptx import Presentation
        prs = Presentation(filepath)
        text = ""
        for slide in prs.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text"):
                    text += shape.text + "\n"
        return text

    elif ext == ".txt":
        return open(filepath, "r", encoding="utf-8").read()
    
    elif ext == ".csv":
        import pandas as pd
        df = pd.read_csv(filepath, encoding="utf-8")
        return df.to_csv(index=False)
    
    elif ext in (".xls", ".xlsx"):
        import pandas as pd

        # è®€å–æ‰€æœ‰å·¥ä½œè¡¨ï¼›pandas æœƒå›å‚³ dict: {sheet_name: DataFrame}
        all_sheets = pd.read_excel(
            filepath,
            sheet_name=None,       # è®€å…¨éƒ¨
            header=None,           # ä¸æŠŠç¬¬ä¸€åˆ—ç•¶æ¬„åï¼Œé¿å…éºæ¼
            engine="openpyxl" if ext == ".xlsx" else "xlrd"
        )

        # æŠŠæ¯å¼µå·¥ä½œè¡¨è½‰æˆæ–‡å­—
        text_parts = []
        for name, df in all_sheets.items():
            # å°‡ NaN è£œç©ºå­—ä¸²ã€æ”¹æˆ strï¼Œå†ä»¥ tab ä¸²åˆ— â†’ æ¯åˆ—åŠ æ›è¡Œ
            body = (
                df.fillna("")
                .astype(str)
                .apply(lambda row: "\t".join(row), axis=1)
                .str.cat(sep="\n")
            )
            text_parts.append(f"--- å·¥ä½œè¡¨: {name} ---\n{body}\n")

        return "\n".join(text_parts)
    
    elif ext == ".json":
        import json

        def _flatten(obj, prefix=""):
            items = {}
            if isinstance(obj, dict):
                for k, v in obj.items():
                    new_key = f"{prefix}.{k}" if prefix else k
                    items.update(_flatten(v, new_key))
            elif isinstance(obj, list):
                for i, v in enumerate(obj):
                    new_key = f"{prefix}[{i}]" if prefix else f"[{i}]"
                    items.update(_flatten(v, new_key))
            else:
                # å°æ–¼åŸºæœ¬é¡å‹ï¼Œç›´æ¥å­˜
                items[prefix] = obj
            return items

        text_parts = []
        with open(filepath, "r", encoding="utf-8") as f:
            # è®€å‰ä¸€å°æ®µåˆ¤æ–·æ˜¯ä¸æ˜¯ NDJSONï¼ˆæ¯è¡Œä¸€å€‹ JSON ç‰©ä»¶ï¼‰
            sample = f.read(2048)
            f.seek(0)
            is_ndjson = False
            try:
                lines = sample.strip().splitlines()
                if len(lines) > 1:
                    # å˜—è©¦è§£æå‰å¹¾è¡Œï¼Œå¦‚æœéƒ½èƒ½ parse æˆ jsonï¼Œèªç‚ºæ˜¯ NDJSON
                    for line in lines[:5]:
                        json.loads(line)
                    is_ndjson = True
            except Exception:
                is_ndjson = False

            if is_ndjson:
                for idx, line in enumerate(f, start=1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        obj = json.loads(line)
                    except json.JSONDecodeError:
                        continue  # è·³é parse å¤±æ•—è¡Œ
                    flat = _flatten(obj)
                    body = "\n".join(f"{k}: {v}" for k, v in flat.items())
                    text_parts.append(f"--- RECORD {idx} ---\n{body}")
            else:
                try:
                    data = json.load(f)
                except json.JSONDecodeError:
                    # å¦‚æœæ•´å€‹ JSON è®€ä¸é€²ä¾†ï¼Œé€€å›åŸå§‹æ–‡å­—
                    f.seek(0)
                    return f.read()
                if isinstance(data, list):
                    for idx, item in enumerate(data, start=1):
                        flat = _flatten(item)
                        body = "\n".join(f"{k}: {v}" for k, v in flat.items())
                        text_parts.append(f"--- ITEM {idx} ---\n{body}")
                elif isinstance(data, dict):
                    flat = _flatten(data)
                    body = "\n".join(f"{k}: {v}" for k, v in flat.items())
                    text_parts.append(body)
                else:
                    text_parts.append(str(data))

        return "\n\n".join(text_parts)
  
    else:
        raise ValueError(f"âŒ ä¸æ”¯æ´çš„æ•™ææ ¼å¼ï¼š{ext}")

def multiline_input(prompt="ä½ ï¼ˆå¯å¤šè¡Œï¼Œç©ºè¡Œé€å‡ºï¼‰ï¼š"):
    print(prompt)
    lines = []
    while True:
        line = input()
        if line.strip() == "":
            break
        lines.append(line)
    return "\n".join(lines)

def main(file_path: str, reset: bool):
    if reset:
        reset_db()

    # è®€å–æ•™æ
    text = convert_to_text(file_path)
    chunks = load_and_chunk(text)
    print(f"å·²åˆ‡å‡º {len(chunks)} ç‰‡")

    vectordb = build_or_load(chunks)
    print("âœ”ï¸ å‘é‡ç´¢å¼•å°±ç·’")

    agent = TutorAgent()

    # æ•™ææ‘˜è¦é–‹å ´
    context = "\n\n---\n\n".join(
        [doc.page_content for doc in vectordb.similarity_search("intro", k=CFG["top_k_intro"])]
    )
    intro_prompt = f"""
ä»¥ä¸‹æ˜¯ä»Šå¤©çš„æ•™æå…§å®¹ï¼Œè«‹å…ˆé–±è®€ä¸¦åˆ—å‡º 2ï½5 å€‹é‡é»ï¼Œç”¨è¦ªåˆ‡èªæ°£é–‹å ´ï¼Œä¸¦è©¢å•å­¸ç”Ÿæ˜¯å¦æº–å‚™å¥½é–‹å§‹å­¸ç¿’ï¼š
æ•™æå…§å®¹ï¼š
{context}
"""
    print("\nåŠ©ç†ï¼š", agent.ask(intro_prompt))

    # å•ç­”äº’å‹•
    while True:
        user_input = multiline_input()

        # === A. é›¢é–‹ç³»çµ± ===
        if user_input.lower() in {"exit", "quit", "bye"}:
            agent.messages.append({"role": "system", "content": "produce_diagnosis"})
            diagnosis = agent.ask(weakness_template)
            print("\nåŠ©ç†ï¼ˆè¨ºæ–·ï¼‰ï¼š\n", diagnosis)
            print("ğŸ‘‹ å†è¦‹ï¼")
            break

        # === B. ä¸€èˆ¬å°è©± ===
        print("\nåŠ©ç†ï¼š", agent.ask(user_input))

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("file", help="æ•™ææª”æ¡ˆè·¯å¾‘ (.pdf/.docx/.pptx/.txt)")
    ap.add_argument("--reset-db", action="store_true", help="é‡æ–°å»ºç«‹å‘é‡åº«")
    args = ap.parse_args()
    main(args.file, args.reset_db)
